<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Abner Hernandez</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<section id="header">
				<header>
					<span class="image avatar"><img src="images/guatemala1.png" alt="" /></span>
					<h1 id="logo">Abner Hernandez</a></h1>
					<p>Linguist<br/>
					<a href="pdfs/Academic_CV.pdf">CV (not updated)</a></p>
				</header>
				<nav id="nav">
					<ul>
						<li><a href="#one">About Me</a></li>
						<li><a href="#two">Projects</a></li>
						<li><a href="#three">Publications</a></li>
			
					</ul>
				</nav>
				<footer>
					<ul class="icons">
						<p>Social Media & Contact</p>
						<li><a href="https://www.linkedin.com/in/abner-hernandez-455377191/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://github.com/abnerLing" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<li><a href="https://www.researchgate.net/profile/Abner_Hernandez2" class="icon brands fa-researchgate"><span class="label">ResearchGate</span></a></li>
						<li><a href="mailto: abner1724@gmail.com" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
						
					</ul>
				</footer>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one">
								<div class="container">
									<h2>About Me</h2>
									<ul>
										<li>Reasearcher for the <a href="https://lme.tf.fau.de/">Pattern Recognition Lab</a> at <a href="https://www.fau.eu/">Friedrich-Alexander-Universität Erlangen-Nürnberg</a> and previous member of the <a href="http://slp.snu.ac.kr/">Spoken Langauge Processing Lab.</a></li>
										<li>My research interests include in speech recoginition, particularly, impaired speech recoginition, along with impaired speech detection. However, I'm also interested in natural language processing and a variety of machine and deep learning applications in the field of linguistics and speech science.</li>
									</ul>
							
									<h2>Education</h2>
									<dl>
										<dt>MA Linguistics, Seoul National Univiersity 2020</dt>
										<dd>- Focus on computational linguistics and phonetics.</dd>
										<dt>BA (Honours) Linguistics, Simon Fraser University 2017</dt>
										<dd>- Focus on phonetics and neurolinguistics.</dd>
									</dl>
																
								</div>
							</section>

							

	

						<!-- Two -->				

														 
								
								<p></p>
							<section id="two">
								<div class="container">
									<h2>Small Projects</h2>
									<p><b>These projects were mostly done during my masters program at Seoul National University</b></p>
									<div class="features">
										<article>
											<a href="https://github.com/abnerLing/dysarthria-asr" class="image"><img src="images/kaldi.png" alt="" /></a>
											<div class="inner">
												<h4><a href="https://github.com/abnerLing/dysarthria-asr">UASpeech ASR kaldi baseline</a></h4>
												<p>This is a baseline kaldi script for a GMM-HMM based acoustic model using the UA-Speech database which is a database for dysarthric speech research. I have also included some options for data augmentation. (note that my DNN-based model using pytorch-kaldi is based on alignments from this model)</p>
											</div>
										</article>
										
										<article>
											<a href="https://github.com/abnerLing/dysarthria-DNN" class="image"><img src="images/pytorch-kaldi_logo.png" alt="" /></a>
											<div class="inner">
												<h4><a href="https://github.com/abnerLing/dysarthria-DNN">Pytorch-Kaldi with the UAspeech database</a></h4>
												<p>This is an example of how to create a configuration file using the pytorch-kaldi toolkit to improve dysarthric speech recognition.</p>
											</div>
										</article>

										<article>
											<a href="https://github.com/abnerLing/dysarthria-voice-clone" class="image"><img src="images/vc.png" alt="" /></a>
											<div class="inner">
												<h4><a href="https://github.com/abnerLing/dysarthria-voice-clone">Voice cloning for Dysarthric Speech</a></h4>
												<p>This is some experimenting I did with voice cloning using two methods PSOLA, and transfer learning TTS. <a href="https://abnerling.github.io/dysarthria-audio-samples/">Audio Samples</a></p></p>
											</div>
										</article>

										<article>
											<a href="https://github.com/abnerLing/dysarthric_speech-classification" class="image"><img src="images/sicss.png" alt="" /></a>
											<div class="inner">
												<h4><a href="https://github.com/abnerLing/dysarthric_speech-classification">Dysarthric speech classification with Fricatives</a></h4>
												<p>This is the code used for my 2019 conference paper "Dysarthria Classification Using Acoustic Properties of Fricatives".</p>
											</div>
										</article>
									</div>
								</div>
							</section>

						<!-- Three -->
						<section id="three">
							<div class="container">
								<h2>Publications</h2>
								
								<ul>
									<li>Hernandez, A., P&eacute;rez, P.A, N&ouml;th, E., Orozco, J.R. (2022) Cross-lingual Self-Supervised Speech Representations for Improved Dysarthric Speech Recognition. To appear in Proc. Interspeech 2022. <a href="https://arxiv.org/pdf/2204.01670.pdf">PDF</a>  <a href="https://arxiv.org/abs/2204.01670">LINK</a></li>
									<li>Hernandez A., Yang S.H. (2021) Multimodal Corpus Analysis of Autoblog 2020: Lecture Videos in Machine Learning. In: Karpov A., Potapova R. (eds) Speech and Computer. SPECOM 2021. Lecture Notes in Computer Science, vol 12997. <a href="https://link.springer.com/content/pdf/10.1007%2F978-3-030-87802-3_24.pdf"> PDF</a> <a href="https://link.springer.com/chapter/10.1007/978-3-030-87802-3_24">LINK</a></li>
									<li>Hernandez, A.; Kim, S.; Chung, M. Prosody-Based Measures for Automatic Severity Assessment of Dysarthric Speech. Applied Sciences 2020, 10, 6999. <a href="https://www.mdpi.com/2076-3417/10/19/6999/pdf"> PDF</a> <a href="https://www.mdpi.com/2076-3417/10/19/6999">LINK</a></li>
									<li>Hernandez, A., Yeo, E.J., Kim, S., Chung, M. (2020) Dysarthria Detection and Severity Assessment Using Rhythm-Based Metrics. Proc. Interspeech 2020, 2897-2901. <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2020/hernandez20_interspeech.pdf">PDF</a>  <a href="https://www.isca-speech.org/archive/interspeech_2020/hernandez20_interspeech.html">LINK</a></li>
									<li>Hernandez, A.; Chung, M.H. Dysarthria Classification Using Acoustic Properties of Fricatives. In Proceedings of the Seoul International Conference on Speech Sciences (SICSS), Seoul, Korea, 15–16 November 2019; pp. 43–44. <a href="pdfs/SICSS_2019_paper.pdf">PDF</a> <a href="https://www.researchgate.net/publication/337313133_Dysarthria_Classification_Using_Acoustic_Properties_of_Fricatives">LINK</a></li>
									<li>Hernandez, A.; Lee, H.Y.; Chung, M.H. Acoustic analysis of fricatives in dysarthric speakers with cerebral palsy. Phonetics and Speech Sciences 2019, 11, 23–29. <a href="https://www.eksss.org/download/download_pdf?pid=pss-11-3-23"> PDF</a> <a href="https://www.eksss.org/archive/view_article?pid=pss-11-3-23">LINK</a></li>
									<li>Sindel, A.; Hernandez, A; Yang, S.H; Christlein, V.; Maier, A. SliTraNet: Automatic Detection of Slide Transitions in Lecture Videos using Convolutional Neural Networks. Proceedings of the OAGM Workshop 2021. Computer Vision and Pattern Analysis Across Domains, 59–64. <a href="https://openlib.tugraz.at/download.php?id=621f329186973&location=browse"> PDF</a> <a href="https://www.researchgate.net/publication/358458365_SliTraNet_Automatic_Detection_of_Slide_Transitions_in_Lecture_Videos_using_Convolutional_Neural_Networks">LINK</a></li>
								</ul>
				
							</div>
						</section>

					</div>

				<!-- Footer -->
					<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
